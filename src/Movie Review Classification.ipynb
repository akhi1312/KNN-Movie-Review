{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing all the Libraries and using Delivered Cosine_Similarty Function \n",
    "import re \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from numpy.linalg import norm\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import pairwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0                                                  1\n",
      "0 -1  Although a film with Bruce Willis is always wo...\n",
      "1 -1  This movie was slower then Molasses in January...\n",
      "2 -1  Interesting film about an actual event that to...\n",
      "3 -1  It's painfully obvious that the people who mad...\n",
      "4  1  This movie really is a mixed bag. On the one h...\n"
     ]
    }
   ],
   "source": [
    "# Reading Training DataSet \n",
    "\n",
    "trainDf = pd.read_csv(\n",
    "    filepath_or_buffer='./train.dat', \n",
    "    header=None, \n",
    "    sep='\\t')\n",
    "\n",
    "print trainDf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0\n",
      "0  I am so glad when i watch in every time the mo...\n",
      "1  when I first heard about this movie, I noticed...\n",
      "2  I saw this on television more years ago than I...\n",
      "3  Peter Boyle was always a great actor and he pr...\n",
      "4  Another entertaining Travolta dance flick! GRE...\n"
     ]
    }
   ],
   "source": [
    "# Reading Test DataSet \n",
    "\n",
    "testDf = pd.read_csv(\n",
    "    filepath_or_buffer='./test.dat', \n",
    "    header=None, \n",
    "    sep='\\t')\n",
    "\n",
    "print testDf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removed All Html Tags and Special Character and Number Except Space  from Trainging and Test data set \n",
    "\n",
    "\n",
    "# TrainingSet\n",
    "trainvalues = trainDf.iloc[:,:].values\n",
    "\n",
    "#print trainvalues\n",
    "\n",
    "trainRatings = []\n",
    "trainReviews = []\n",
    "\n",
    "for value in trainvalues:\n",
    "    trainRatings.append(value[0])\n",
    "    trainReviews.append(re.sub('[^A-z -]', '', re.sub('<[^>]*>','',value[1])).lower())\n",
    "    \n",
    "\n",
    "# TestSet \n",
    "\n",
    "testvalues = testDf.iloc[:,:].values\n",
    "testReviews = []\n",
    "\n",
    "for value in testvalues:\n",
    "    testReviews.append(re.sub('[^A-z -]', '', re.sub('<[^>]*>','',value[0])).lower())\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterLen(docs, minlen):\n",
    "    return[ [t for t in d if len(t) >= minlen ] for d in docs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1985\n",
      "1549\n",
      "225\n",
      "156\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Removing All words whose lenth is less than 4 as those words \n",
    "doesnot add any value to analysis it is just a noise for us .\n",
    "'''\n",
    "\n",
    "trainDocs = [l.split() for l in trainReviews]\n",
    "testDocs = [l.split() for l in testReviews]\n",
    "\n",
    "trainDocs1 = filterLen(trainDocs,5)\n",
    "testDocs1 =  filterLen(testDocs ,5)\n",
    "\n",
    "#Before Processing \n",
    "\n",
    "print len(trainReviews[0])\n",
    "print len(testReviews[0])\n",
    "\n",
    "#After Processing \n",
    "\n",
    "print len(trainDocs1[0])\n",
    "print len(testDocs1[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combinedList = trainDocs1 + testDocs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_matrix(docs):\n",
    "    r\"\"\" Build sparse matrix from a list of documents, \n",
    "    each of which is a list of word/terms in the document.  \n",
    "    \"\"\"\n",
    "    nrows = len(docs)\n",
    "    idx = {}\n",
    "    tid = 0\n",
    "    nnz = 0\n",
    "    for d in docs:\n",
    "        nnz += len(set(d))\n",
    "        for w in d:\n",
    "            if w not in idx:\n",
    "                idx[w] = tid\n",
    "                tid += 1\n",
    "    ncols = len(idx)\n",
    "        \n",
    "    # set up memory\n",
    "    ind = np.zeros(nnz, dtype=np.int)\n",
    "    val = np.zeros(nnz, dtype=np.double)\n",
    "    ptr = np.zeros(nrows+1, dtype=np.int)\n",
    "    i = 0  # document ID / row counter\n",
    "    n = 0  # non-zero counter\n",
    "    # transfer values\n",
    "    for d in docs:\n",
    "        cnt = Counter(d)\n",
    "        keys = list(k for k,_ in cnt.most_common())\n",
    "        l = len(keys)\n",
    "        for j,k in enumerate(keys):\n",
    "            ind[j+n] = idx[k]\n",
    "            val[j+n] = cnt[k]\n",
    "        ptr[i+1] = ptr[i] + l\n",
    "        n += l\n",
    "        i += 1\n",
    "            \n",
    "    mat = csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype=np.double)\n",
    "    mat.sort_indices()\n",
    "    \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combinedMatrix = build_matrix(combinedList)\n",
    "combinedMatrix.shape\n",
    "trainMatrix = combinedMatrix[0:25000]\n",
    "testMatrix = combinedMatrix[25000:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity_n_space(m1, m2, batch_size=10):\n",
    "    assert m1.shape[1] == m2.shape[1]\n",
    "    ret = np.ndarray((m1.shape[0], m2.shape[0]))\n",
    "    for row_i in range(0, int(m1.shape[0] / batch_size) + 1):\n",
    "        start = row_i * batch_size\n",
    "        end = min([(row_i + 1) * batch_size, m1.shape[0]])\n",
    "        if end <= start:\n",
    "            break # cause I'm too lazy to elegantly handle edge cases\n",
    "        rows = m1[start: end]\n",
    "        sim = cosine_similarity(rows, m2) # rows is O(1) size\n",
    "        ret[start: end] = sim\n",
    "    return ret\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cosineSimilarityValue = cosine_similarity_n_space(testMatrix,trainMatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('count : ', 0)\n",
      "--The End--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f = open('./format.dat', 'w')\n",
    "count = 0\n",
    "testIndex = 0\n",
    "for row in cosineSimilarityValue:\n",
    "\n",
    "    \n",
    "    #kneighbours = heapq.nlargest(5, row)\n",
    "    k=71\n",
    "    partitioned_row_byindex = np.argpartition(-row, k)  \n",
    "    similar_index = partitioned_row_byindex[:k]\n",
    "\n",
    "    \n",
    "    ReviewTypeNegative = 0\n",
    "    ReviewTypePositive = 0\n",
    "\n",
    "    for index in similar_index:\n",
    "\n",
    "        if trainvalues[index][0] == -1:\n",
    "               ReviewTypeNegative+=1\n",
    "        elif trainvalues[index][0] == 1:\n",
    "               ReviewTypePositive+=1\n",
    "            \n",
    "    \n",
    "    if ReviewTypeNegative > ReviewTypePositive:\n",
    "        f.write('-1\\n')\n",
    "        count +=1\n",
    "    else:\n",
    "        f.write('+1\\n')\n",
    "        count +=1\n",
    "        \n",
    "print(\"count : \",count)\n",
    "print(\"TestIndex\" , testIndex)\n",
    "print(\"--The End--\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
